---
title: "Dada2_quick"
author: "RGS"
date: ""
output: html_document
params:
  folder:
    value: "C:/Users/RG.5015511/Documents/Projects/Mar_Menor/test_demult"
  hash:
    value: "yes"
  cont:
    value: "no"

  
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir=params$folder)
```

## Dada2 report

You have successfully split your libraries into a pair (or two) of fastq files per sample. Now let's import the output of demultiplex_both_fastq.sh

First load the packages. And let's update the parameters we need
```{r loading packages, echo=FALSE ,message=FALSE}
#library (devtools)
library (tidyverse)
library (stringr)
library (dada2)
library (Biostrings)
library (digest)
library (rlang)



 path1 <- params$folder
#path1 <- file.path(params$folder, "demultiplexed")
list.dirs(path1, full.names = F )[-1]  -> tests

# Function to summarise data

getN <- function(x) sum(getUniques(x))

```
Firstly, we'll find the patterns that separate our Fwd, Rev, .1 and .2 files. look at the quality of the .1 and .2 reads

```{r one function }

analyze_folder<- function(folder){
  
F1s <- sort(list.files(file.path(path1,folder), pattern="_Fwd.1.fastq", full.names = TRUE, recursive = F))
F2s <- sort(list.files(file.path(path1,folder), pattern="_Fwd.2.fastq", full.names = TRUE, recursive = F))
R1s <- sort(list.files(file.path(path1,folder), pattern="_Rev.1.fastq", full.names = TRUE, recursive = F))
R2s <- sort(list.files(file.path(path1,folder), pattern="_Rev.2.fastq", full.names = TRUE, recursive = F))

# Filter

filt_path <- file.path(path1,folder, "/filtered_220_120") # Place filtered files in filtered/ subdirectory

filt_renamer <- function(filename){
  
  dir1 <- dirname(filename)
  basename1 <- basename(filename)
  
  file.path(dir1, "filtered_220_120", basename1)
}

filtF1s <- filt_renamer(F1s)
filtF2s <-filt_renamer(F2s)
out_Fs <- filterAndTrim(F1s, filtF1s, F2s, filtF2s,
   truncLen=c(220,160),
                      maxN=0, maxEE=c(2,2),
   # truncQ=10, rm.phix=TRUE,
                      compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE


names(filtF2s) <- names(filtF1s)  <- basename(filtF1s)


rownames(out_Fs) <- basename(filtF1s)

filtR1s <- filt_renamer(R1s)
filtR2s <- filt_renamer(R2s)
out_Rs <- filterAndTrim(R1s, filtR1s, R2s, filtR2s,
  truncLen=c(220,160),
                      maxN=0, maxEE=c(2,2),
  # truncQ=10, rm.phix=TRUE,
                      compress=TRUE, multithread=TRUE)

names(filtR2s) <- names(filtR1s)  <- basename(filtR1s)
rownames(out_Rs) <- basename(filtR1s)

out_Fs_tibble<-tibble(file=dimnames(out_Fs)[[1]], reads.in = out_Fs[,1], reads.out=out_Fs[,2], direction = "Fwd")
out_Rs_tibble<-tibble(file=dimnames(out_Rs)[[1]], reads.in = out_Rs[,1], reads.out=out_Rs[,2], direction = "Rev")

bind_rows(out_Fs_tibble, out_Rs_tibble) %>%
  group_by(direction) %>%
  summarise (across(where(is.numeric), sum))

filtF1s[out_Fs_tibble$reads.out>20] -> filtF1s_good
filtF2s[out_Fs_tibble$reads.out>20] -> filtF2s_good

filtR1s[out_Rs_tibble$reads.out>20] -> filtR1s_good
filtR2s[out_Rs_tibble$reads.out>20] -> filtR2s_good

errF1 <- learnErrors(filtF1s_good, multithread=TRUE,verbose = 0)
errF2 <- learnErrors(filtF2s_good, multithread=TRUE,verbose = 0)
errR1 <- learnErrors(filtR1s_good, multithread=TRUE,verbose = 0)
errR2 <- learnErrors(filtR2s_good, multithread=TRUE,verbose = 0)

derepF1s <- derepFastq(filtF1s_good, verbose=TRUE)



derepF2s <- derepFastq(filtF2s_good, verbose=TRUE)



derepR1s <- derepFastq(filtR1s_good, verbose=TRUE)



derepR2s <- derepFastq(filtR2s_good, verbose=TRUE)





dadaF1s <- dada(derepF1s, err = errF1, multithread = TRUE)

dadaF2s <- dada(derepF2s, err = errF2, multithread = TRUE)


dadaR1s <- dada(derepR1s, err = errR1, multithread = TRUE)

dadaR2s <- dada(derepR2s, err = errR2, multithread = TRUE)



mergersF <- mergePairs(dadaF1s,
                       derepF1s,
                       dadaF2s,
                       derepF2s,
                       verbose = 0)


mergersR <- mergePairs(dadaR1s,
                       derepR1s,
                       dadaR2s,
                       derepR2s,
                       verbose = 0)



summary.fun <- function(list.of.step){

  name.step <- deparse(substitute(list.of.step))

  map_dfc(list.of.step, getN) %>%
   pivot_longer(everything(), names_to = "sample", values_to = "value") %>%
  mutate(step = name.step)
}
# 
# summary.fun(dadaF1s)#%>%
#   bind_rows(summary.fun(dadaF2s)) %>%
#   bind_rows(summary.fun(dadaR1s)) %>%
#   bind_rows(summary.fun(dadaR2s)) %>%
#   bind_rows(summary.fun(derepF1s)) %>%
#   bind_rows(summary.fun(derepF2s)) %>%
#   bind_rows(summary.fun(mergersF))-> summary.stats
# # 
# out_Fs %>%
#   as.data.frame() %>%
#   rownames_to_column("file") %>%
#   dplyr::rename(reads.in.fwd =2, filtered.fwd = 3) %>%
#   pivot_longer(-file, names_to = "step") %>%
#   mutate (fastq_header = str_remove(file, "_Fwd.1.fastq")) %>%
#   left_join(sample.map) %>%
#   select(sample = Sample, step, value) %>%
#   bind_rows(summary.stats) -> summary.stats
# 
# summary.stats %>%
#   bind_rows(summary.fun(derepR1s)) %>%
#   bind_rows(summary.fun(derepR2s)) %>%
#   bind_rows(summary.fun(mergersR)) -> summary.stats
# 
# out_Rs %>%
#   as.data.frame() %>%
#   rownames_to_column("file") %>%
#   dplyr::rename(reads.in.rev =2, filtered.rev = 3) %>%
#   pivot_longer(-file, names_to = "step") %>%
#   mutate (fastq_header = str_remove(file, "_Rev.1.fastq")) %>%
#   left_join(sample.map) %>%
#   select(sample = Sample, step, value) %>%
#   bind_rows(summary.stats) -> summary.stats

seqtabF <- makeSequenceTable(mergersF)

dim(seqtabF)

# rowSums(seqtabF) %>%
#   as.data.frame() %>%
#   rownames_to_column("sample") %>%
#   dplyr::rename(value = 2) %>%
#   mutate(step = "Tabled.fwd") %>%
#   bind_rows(summary.stats) -> summary.stats

table(nchar(getSequences(seqtabF)))

seqtabR <- makeSequenceTable(mergersR)

dim(seqtabR)

nchar(getSequences(seqtabR)) %>% as.data.frame() %>%
  dplyr::rename(length = 1) %>%
  ggplot(aes(x = length)) + geom_density()

# rowSums(seqtabR) %>%
#   as.data.frame() %>%
#   rownames_to_column("sample") %>%
#   dplyr::rename(value = 2) %>%
#   mutate(step = "Tabled.rev") %>%
#   bind_rows(summary.stats) -> summary.stats

reversed_sequences<-as.character(reverseComplement(DNAStringSet(colnames(seqtabR))))

summary (colnames(seqtabF) %in% reversed_sequences)

summary (reversed_sequences %in% colnames(seqtabF))

colnames(seqtabR)<-reversed_sequences

seqtab.R.df=as.data.frame(seqtabR)

seqtab.R.df %>%
  rownames_to_column("sample") %>%
  pivot_longer(-sample, names_to = "sequence", values_to = "nReads_R") -> seqtab.R.df

seqtab.F.df=as.data.frame(seqtabF)
seqtab.F.df %>%
  rownames_to_column("sample") %>%
  pivot_longer(-sample, names_to = "sequence", values_to = "nReads_F") -> seqtab.F.df

full_join(seqtab.R.df, seqtab.F.df) %>%
  replace_na(list(nReads_R = 0, nReads_F = 0)) %>%
  group_by(sample,sequence ) %>%
  mutate(nReads = sum(nReads_R + nReads_F)) %>%
  select(sample, sequence, nReads)  %>%
  pivot_wider(id_cols = sample, names_from = sequence, values_from = nReads, values_fill = 0) -> full_df



final.seqtab <- full_df %>%
  ungroup() %>%
  select(-sample) %>%
  # mutate_all(as.numeric) %>% 
  as.matrix()

dimnames(final.seqtab)[[1]] <- full_df$sample


# rowSums(final.seqtab) %>%
#   as.data.frame() %>%
#   rownames_to_column("sample") %>%
#   dplyr::rename(value = 2) %>%
#   mutate(step = "Tabled") %>%
#   bind_rows(summary.stats) -> summary.stats

seqtab.nochim <- removeBimeraDenovo(final.seqtab, method="consensus", multithread=TRUE)

dim(seqtab.nochim)

table(nchar(getSequences(seqtab.nochim)))

seqtab.nochim.df=as.data.frame(seqtab.nochim)

ASV.file <- file.path(path1,folder, "ASV_table_220.csv")

# Now decide if you want hashing or not

  conv_file <-  file.path(path1,folder,"hash_key_220.csv")
  conv_fasta<-  file.path(path1,folder, "hash_key.fasta")
 
  conv_table <- tibble( Hash = "", Sequence ="")

  #hashes <- list(NULL)

  map_chr (colnames(seqtab.nochim.df), ~ digest(.x, algo = "sha1", serialize = F, skip = "auto")) -> Hashes
  conv_table <- tibble (Hash = Hashes,
                        Sequence = colnames(seqtab.nochim.df))

  colnames(seqtab.nochim.df) <- Hashes


  write_csv(conv_table, conv_file)
  seqinr::write.fasta(  sequences = as.list(conv_table$Sequence),
                        names     = as.list(conv_table$Hash),
                        file.out  = conv_fasta)


seqtab.nochim.df %>%
  rownames_to_column("sample") %>%
  pivot_longer(-sample, names_to="Hash", values_to = "nReads") %>%
  filter (nReads > 0) -> current_asv

write_csv(current_asv, ASV.file)



}




```

Map the function across
folders

```{r}
tests |> 
  map(analyze_folder) |> 
  set_names(nm = tests)
```

```{r}
tests <- c("restrictive", "tolerant")
tests |> 
  map(~read_csv(file = file.path (path1, .x, "ASV_table_220.csv"))) |> 
  set_names(nm = tests) |> 
  bind_rows(.id = "Test") -> ASVs
tests |> 
  map(~read_csv(file = file.path (path1, .x, "hash_key_220.csv"))) |> 
  set_names(nm = tests) |> 
  bind_rows() |> 
  distinct()-> Hashes

left_join(ASVs, Hashes) |> 
  mutate(seqlen = str_length(Sequence)) |> 
  filter (!str_detect(Test, "filtered" )) |> 
  ggplot (aes(x = Test, y = nReads, fill = as.factor(seqlen)  )) +
  geom_col()

left_join(ASVs, Hashes) |> 
  mutate(seqlen = str_length(Sequence)) |> 
  filter (!str_detect(Test, "filtered" )) |> 
  ggplot(aes(x =seqlen)) +
  geom_histogram()+
  facet_wrap(~ Test)

left_join(ASVs, Hashes) |> 
  mutate(seqlen = str_length(Sequence)) |> 
  filter (!str_detect(Test, "filtered" )) |> 
  ggplot(aes(x =seqlen)) +
  geom_density()+
  facet_wrap(~ Test)

left_join(ASVs, Hashes) |> 
  mutate(seqlen = str_length(Sequence)) |> 
  filter (!str_detect(Test, "filtered" )) |> 
 
  ggplot(aes(x =seqlen, y= nReads)) +
  geom_col(aes(fill = as.factor(seqlen))) +
  facet_wrap(~ Test)



```

Let's group the ASVs by length

```{r}
left_join(ASVs, Hashes) |> 
  mutate(seqlen = str_length(Sequence)) |> 
  filter (!str_detect(Test, "filtered" )) |> 
  group_by(seqlen, Test) |> 
  summarise (nASVs = n_distinct(Hash),
             nR =    sum(nReads)) |> 
  arrange(desc(nR)) |> 
   mutate (length = case_when (seqlen == 313 ~ "313",
                              is.integer((seqlen-313)/3)  ~ as.character(seqlen) ,
                              TRUE                       ~ "Artifact")) |> 
   ggplot(aes(x =seqlen, y= nR)) +
  geom_col(aes(fill = length)) +
  facet_wrap(~ Test)
```



